# Whisperrr - AI-Powered Audio Transcription Platform

A production-ready, full-stack audio transcription platform that leverages OpenAI's Whisper library to provide high-quality speech-to-text conversion. Built with modern technologies including Spring Boot, FastAPI, and React TypeScript, Whisperrr offers a scalable, maintainable solution for audio transcription needs.

## ğŸ¯ Project Vision

Whisperrr transforms audio content into accurate, searchable text using state-of-the-art AI technology with **instant results**. Whether you're transcribing interviews, meetings, podcasts, or any audio content, Whisperrr provides professional-grade transcription with an intuitive user interface and simplified, database-free architecture.

## âš¡ Key Benefits

### ğŸš€ **Instant Transcription**
- **No Waiting**: Upload a file and get results immediately
- **No Polling**: Results appear instantly without status checking
- **Real-Time Feedback**: See transcription as soon as processing completes

### ğŸ¯ **Simplified Architecture**
- **No Database Required**: Zero setup complexity
- **Stateless Operation**: No job queuing or persistence overhead
- **Direct Processing**: Streamlined communication between services
- **Easy Deployment**: Fewer moving parts, easier maintenance

## ğŸ—ï¸ System Architecture

Whisperrr follows a simplified, lightweight architecture focused on instant transcription:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Whisperrr Platform                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚                 â”‚    â”‚                 â”‚    â”‚             â”‚ â”‚
â”‚  â”‚  React Frontend â”‚â—„â”€â”€â–ºâ”‚ Spring Boot API â”‚â—„â”€â”€â–ºâ”‚   Python    â”‚ â”‚
â”‚  â”‚   (Port 3000)   â”‚    â”‚   (Port 8080)   â”‚    â”‚  Service    â”‚ â”‚
â”‚  â”‚                 â”‚    â”‚                 â”‚    â”‚ (Port 8000) â”‚ â”‚
â”‚  â”‚  â€¢ File Upload  â”‚    â”‚ â€¢ REST Proxy    â”‚    â”‚ â€¢ Whisper AIâ”‚ â”‚
â”‚  â”‚  â€¢ Instant UI   â”‚    â”‚ â€¢ Validation    â”‚    â”‚ â€¢ Direct    â”‚ â”‚
â”‚  â”‚  â€¢ Results View â”‚    â”‚ â€¢ Error Handle  â”‚    â”‚   Processingâ”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚           â”‚                       â”‚                      â”‚     â”‚
â”‚           â”‚                       â”‚                      â”‚     â”‚
â”‚           â–¼                       â–¼                      â–¼     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”‚              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚   Web Browser   â”‚              â”‚              â”‚   Whisper   â”‚ â”‚
â”‚  â”‚    (Client)     â”‚              â”‚              â”‚   Models    â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â”‚              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                   â”‚                              â”‚
â”‚                          No Database Required                   â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Service Responsibilities

- **React Frontend**: Modern, responsive UI with instant transcription results
- **Spring Boot API**: Lightweight proxy for validation and error handling
- **Python Service**: AI-powered transcription using OpenAI Whisper models
- **No Database**: Stateless operation with instant results

## ğŸ‰ What's New in Version 2.0

### âš¡ **Instant Transcription**
The biggest improvement in Whisperrr 2.0 is the removal of the database layer and job queuing system. Now you get:

- **âœ… Instant Results**: Upload a file, get transcription immediately
- **âœ… No Setup Complexity**: No database installation or configuration
- **âœ… Simplified Deployment**: Just 3 services instead of 4
- **âœ… Better Performance**: Direct processing without overhead
- **âœ… Easier Debugging**: Fewer moving parts, clearer error messages

### ğŸ”„ **Migration from v1.0**
If you were using the previous version with database:
- **No data migration needed**: Previous transcriptions were not persistent anyway
- **Simpler setup**: Remove PostgreSQL installation steps
- **Same API quality**: All transcription features remain the same
- **Better user experience**: Instant feedback instead of polling

## âœ¨ Key Features

### ğŸ¤ Audio Transcription
- **High Accuracy**: Powered by OpenAI's Whisper AI models (tiny to large)
- **Multi-Language**: Support for 99+ languages with automatic detection
- **Multiple Formats**: MP3, WAV, M4A, FLAC, OGG, WMA (up to 25MB)
- **Real-Time Processing**: Live status updates with progress tracking
- **Quality Options**: Choose model size based on accuracy vs speed needs

### ğŸ–¥ï¸ User Experience
- **Drag & Drop Upload**: Intuitive file upload with visual feedback
- **Responsive Design**: Works seamlessly on desktop and mobile devices
- **Dark Mode Support**: Modern UI with theme switching
- **Real-Time Status**: Live progress monitoring with automatic polling
- **Rich Results**: Detailed transcription with timing and confidence scores

### ğŸ”§ Technical Excellence
- **Simplified Architecture**: Lightweight, maintainable service separation
- **Production Ready**: Comprehensive error handling and monitoring
- **Stateless Operation**: No database setup or maintenance required
- **RESTful APIs**: Clean, documented endpoints with OpenAPI specs
- **Docker Support**: Containerized deployment with Docker Compose

### ğŸš€ Performance & Scalability
- **Direct Processing**: Instant transcription without queuing overhead
- **Model Caching**: Efficient memory management and model reuse
- **Stateless Design**: No database bottlenecks or connection limits
- **Concurrent Processing**: Multiple transcription requests simultaneously
- **Health Monitoring**: Built-in health checks and metrics

## ğŸ“ Project Structure

```
Whisperrr/
â”œâ”€â”€ ğŸ“„ README.md                    # This comprehensive guide
â”œâ”€â”€ ğŸ“„ OVERVIEW.md                  # Detailed technical overview
â”œâ”€â”€ ğŸ“„ LICENSE                      # MIT License
â”œâ”€â”€ ğŸ³ docker-compose.yml           # Docker Compose configuration
â”‚
â”œâ”€â”€ ğŸ–¥ï¸ frontend/                    # React TypeScript Frontend
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ components/            # Reusable UI components
â”‚   â”‚   â”œâ”€â”€ hooks/                 # Custom React hooks
â”‚   â”‚   â”œâ”€â”€ pages/                 # Route-level components
â”‚   â”‚   â”œâ”€â”€ services/              # API communication layer
â”‚   â”‚   â”œâ”€â”€ types/                 # TypeScript definitions
â”‚   â”‚   â””â”€â”€ utils/                 # Helper functions
â”‚   â”œâ”€â”€ package.json               # Node.js dependencies
â”‚   â””â”€â”€ ğŸ³ Dockerfile              # Container configuration
â”‚
â”œâ”€â”€ âš™ï¸ backend/                     # Spring Boot API Proxy
â”‚   â”œâ”€â”€ src/main/java/com/shangmin/whisperrr/
â”‚   â”‚   â”œâ”€â”€ config/                # Configuration classes
â”‚   â”‚   â”œâ”€â”€ controller/            # REST API endpoints
â”‚   â”‚   â”œâ”€â”€ dto/                   # Data Transfer Objects
â”‚   â”‚   â”œâ”€â”€ enums/                 # Enumeration types
â”‚   â”‚   â”œâ”€â”€ exception/             # Error handling
â”‚   â”‚   â””â”€â”€ service/               # Business logic
â”‚   â”œâ”€â”€ src/main/resources/
â”‚   â”‚   â””â”€â”€ application.properties # Configuration
â”‚   â”œâ”€â”€ pom.xml                    # Maven dependencies
â”‚   â””â”€â”€ ğŸ³ Dockerfile              # Container configuration
â”‚
â””â”€â”€ ğŸ python-service/             # FastAPI Transcription Service
    â”œâ”€â”€ app/
    â”‚   â”œâ”€â”€ main.py                # FastAPI application
    â”‚   â”œâ”€â”€ config.py              # Configuration management
    â”‚   â”œâ”€â”€ models.py              # Pydantic data models
    â”‚   â”œâ”€â”€ whisper_service.py     # Core transcription logic
    â”‚   â”œâ”€â”€ exceptions.py          # Custom exceptions
    â”‚   â””â”€â”€ utils.py               # Utility functions
    â”œâ”€â”€ requirements.txt           # Python dependencies
    â”œâ”€â”€ venv/                      # Virtual environment
    â””â”€â”€ ğŸ³ Dockerfile              # Container configuration
```

## ğŸš€ Quick Start

### ğŸ“‹ Prerequisites

Ensure you have the following installed on your system:

- **Docker** - For running the application
- **Docker Compose v2** - For orchestrating multiple services

*Note: No database required! Whisperrr now provides instant transcription without persistence.*

### âš¡ Quick Start with Docker Compose

The fastest way to get Whisperrr running:

```bash
# Clone the repository
git clone <repository-url>
cd Whisperrr

# Install docker (MacOS)
brew install --cask docker-desktop

# Start all services with Docker Compose v2
docker compose up -d

# Access the application
# Frontend: http://localhost:3000
# Backend API: http://localhost:8080
# Python Service: http://localhost:8000
```

To view logs:
```bash
docker compose logs -f
```

To stop all services:
```bash
docker compose down
```

## âš™ï¸ Configuration

### ğŸ”§ Environment Variables

Each service can be configured via environment variables for different deployment scenarios:

#### Backend Configuration (`backend/src/main/resources/application.properties`)

```properties
# Application Configuration
spring.application.name=whisperrr-api
server.port=8080

# CORS Configuration (for frontend communication)
cors.allowed-origins=http://localhost:3000,http://localhost:3001
cors.allowed-methods=GET,POST,PUT,DELETE,OPTIONS
cors.allowed-headers=*
cors.allow-credentials=true

# Python Service Integration
whisperrr.service.url=http://localhost:8000
whisperrr.service.timeout=300000

# File Upload Limits
spring.servlet.multipart.max-file-size=25MB
spring.servlet.multipart.max-request-size=25MB

# Logging Configuration
logging.level.com.shangmin.whisperrr=INFO
logging.level.org.springframework.web=INFO

# Actuator Configuration
management.endpoints.web.exposure.include=health,info,metrics
```

#### Python Service Configuration (`python-service/.env`)

```bash
# Whisper Model Configuration
MODEL_SIZE=base                    # tiny, base, small, medium, large
MAX_FILE_SIZE_MB=25               # Maximum upload size
UPLOAD_DIR=/tmp/whisperrr_uploads # Temporary file storage

# API Configuration
LOG_LEVEL=INFO                    # DEBUG, INFO, WARNING, ERROR
MAX_CONCURRENT_TRANSCRIPTIONS=3   # Parallel processing limit
REQUEST_TIMEOUT_SECONDS=300       # Request timeout

# CORS Configuration
CORS_ORIGINS=http://localhost:8080,http://localhost:3000

# Performance Settings
CLEANUP_TEMP_FILES=true          # Automatic cleanup
ENABLE_METRICS=true              # Performance monitoring
```

#### Frontend Configuration (`frontend/.env`)

```bash
# API Configuration
REACT_APP_API_URL=http://localhost:8080/api  # Backend API URL
REACT_APP_POLLING_INTERVAL=2000              # Status polling interval (ms)

# File Upload Configuration  
REACT_APP_MAX_FILE_SIZE=25                   # Max file size (MB)

# Feature Flags
REACT_APP_ENABLE_DEBUG=false                 # Debug mode
REACT_APP_ENABLE_ANALYTICS=false             # Analytics tracking
```

### ğŸ³ Docker Configuration

For containerized deployment, override settings via docker-compose.yml (using `docker compose` command):

```yaml
services:
  backend:
    environment:
      - SPRING_DATASOURCE_URL=jdbc:postgresql://postgres:5432/transcription_db
      - WHISPERRR_SERVICE_URL=http://python-service:8000
      
  python-service:
    environment:
      - MODEL_SIZE=large
      - MAX_CONCURRENT_TRANSCRIPTIONS=5
      
  frontend:
    environment:
      - REACT_APP_API_URL=http://localhost:8080/api
```

## ğŸŒ API Documentation

### ğŸ“‹ Backend API Endpoints (Port 8080)

| Method | Endpoint | Description | Request | Response |
|--------|----------|-------------|---------|----------|
| `POST` | `/api/audio/transcribe` | Upload and transcribe audio file instantly | `multipart/form-data` | `TranscriptionResultResponse` |
| `GET` | `/api/audio/health` | Service health check | None | Health status |

#### Example API Usage

```bash
# Upload and transcribe audio file (get instant results)
curl -X POST http://localhost:8080/api/audio/transcribe \
  -F "audioFile=@recording.mp3"

# Response includes complete transcription results immediately
```

### ğŸ Python Service Endpoints (Port 8000)

| Method | Endpoint | Description | Parameters | Response |
|--------|----------|-------------|------------|----------|
| `POST` | `/transcribe` | Direct audio transcription | `file`, `model_size`, `language` | `TranscriptionResponse` |
| `GET` | `/health` | Service health and model status | None | `HealthResponse` |
| `GET` | `/model/info` | Current model information | None | `ModelInfoResponse` |
| `POST` | `/model/load/{model_size}` | Load specific Whisper model | Model size | Load confirmation |

#### Interactive API Documentation

- **Swagger UI**: http://localhost:8000/docs
- **ReDoc**: http://localhost:8000/redoc

### ğŸ“Š Response Example

#### Direct Transcription Response
```json
{
  "transcriptionText": "Hello, this is a sample transcription of your audio file. The quality is excellent and the speech is clear.",
  "language": "en",
  "confidence": 0.95,
  "duration": 120.5,
  "modelUsed": "base",
  "processingTime": 8.3,
  "completedAt": "2024-01-15T10:32:15.456Z",
  "status": "COMPLETED"
}
```

## ğŸ¯ How to Use Whisperrr

### ğŸ“ Simple Transcription Process

1. **ğŸš€ Start the Application**
   - Ensure backend and Python services are running (see Quick Start above)
   - Open your browser to `http://localhost:3000`

2. **ğŸ“ Upload Your Audio File**
   - Drag and drop an audio file onto the upload area, or
   - Click to browse and select a file from your computer
   - Supported formats: MP3, WAV, M4A, FLAC, OGG, WMA (max 25MB)

3. **âš¡ Get Instant Results**
   - Transcription happens immediately - no waiting or polling!
   - View complete transcription results as soon as processing finishes
   - See confidence scores, detected language, and processing time
   - Copy or export results as needed

### ğŸ›ï¸ Whisper Model Options

Choose the right model for your needs:

| Model | Size | Speed | Accuracy | Best For |
|-------|------|-------|----------|----------|
| `tiny` | 39 MB | ~32x realtime | Basic | Quick drafts, testing |
| `base` | 74 MB | ~16x realtime | Good | General use (default) |
| `small` | 244 MB | ~6x realtime | Better | Balanced quality/speed |
| `medium` | 769 MB | ~2x realtime | High | Important content |
| `large` | 1550 MB | ~1x realtime | Highest | Maximum accuracy |

### ğŸŒ Language Support

Whisperrr automatically detects the language of your audio, or you can specify:

- **99+ Languages Supported**: English, Spanish, French, German, Chinese, Japanese, and many more
- **Automatic Detection**: No need to specify language in most cases
- **Language Hints**: Improve accuracy by specifying the expected language
- **Multilingual Content**: Handles mixed-language audio effectively

### ğŸ’¡ Tips for Best Results

- **Audio Quality**: Higher quality audio produces better transcriptions
- **Clear Speech**: Minimize background noise and ensure clear pronunciation
- **File Format**: WAV and FLAC provide the best quality, MP3 is most convenient
- **Length**: Longer files may take more time but are handled efficiently
- **Model Selection**: Use larger models for important or difficult audio

## ğŸš€ Deployment Options

### ğŸ”§ Development Environment

Perfect for local development with hot reload:

```bash
# Start all services with Docker Compose
docker compose up -d

# Services will be available at:
# Frontend: http://localhost:3000
# Backend: http://localhost:8080
# Python Service: http://localhost:8000
```

### ğŸ³ Docker Deployment

Consistent environment across all platforms:

```bash
# Start all services in detached mode
docker compose up -d

# View logs
docker compose logs -f

# Stop all services
docker compose down

# Rebuild and start
docker compose up -d --build
```

### â˜ï¸ Cloud Deployment Options

#### Option 1: Microservices (Recommended for Scale)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Cloud Architecture                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                             â”‚
â”‚  Frontend (CDN)     Backend (Container)    Python (Serverless) â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚ Vercel      â”‚    â”‚ AWS ECS         â”‚    â”‚ AWS Lambda  â”‚ â”‚
â”‚  â”‚ Netlify     â”‚    â”‚ Google Cloud    â”‚    â”‚ Google      â”‚ â”‚
â”‚  â”‚ Cloudflare  â”‚    â”‚ Run             â”‚    â”‚ Cloud Fn    â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                                             â”‚
â”‚                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                     â”‚
â”‚                    â”‚ Managed DB      â”‚                     â”‚
â”‚                    â”‚ AWS RDS         â”‚                     â”‚
â”‚                    â”‚ Google Cloud    â”‚                     â”‚
â”‚                    â”‚ SQL             â”‚                     â”‚
â”‚                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

#### Option 2: Container Orchestration

```bash
# Kubernetes deployment
kubectl apply -f k8s/

# Docker Swarm deployment  
docker stack deploy -c docker-stack.yml whisperrr
```

#### Option 3: Platform-as-a-Service

```bash
# Heroku deployment
git push heroku main

# Railway deployment
railway up

# Render deployment
render deploy
```

### ğŸ”’ Production Considerations

#### Security
- Enable HTTPS/TLS for all services
- Configure proper CORS origins
- Use environment variables for secrets
- Implement rate limiting
- Enable audit logging

#### Performance
- Use CDN for frontend assets
- Configure database connection pooling
- Implement caching strategies
- Monitor resource usage
- Set up auto-scaling

#### Monitoring
- Health check endpoints: `/actuator/health`, `/health`
- Application metrics and logging
- Database performance monitoring
- Error tracking and alerting
- Uptime monitoring

### ğŸ“Š Environment-Specific Configuration

#### Production Environment Variables

```bash
# Backend
SPRING_PROFILES_ACTIVE=production
SPRING_DATASOURCE_URL=jdbc:postgresql://prod-db:5432/whisperrr
CORS_ALLOWED_ORIGINS=https://yourdomain.com

# Python Service  
MODEL_SIZE=large
MAX_CONCURRENT_TRANSCRIPTIONS=10
LOG_LEVEL=INFO

# Frontend
REACT_APP_API_URL=https://api.yourdomain.com
REACT_APP_ENVIRONMENT=production
```

## ğŸ§ª Testing & Quality Assurance

### ğŸ” Running Tests

#### Backend Tests (Spring Boot)
```bash
cd backend

# Run all tests
./mvnw test

# Run with coverage
./mvnw test jacoco:report

# Run specific test class
./mvnw test -Dtest=AudioControllerTest

# Integration tests
./mvnw test -Dtest=*IntegrationTest
```

#### Frontend Tests (React)
```bash
cd frontend

# Run all tests
npm test

# Run tests with coverage
npm run test:coverage

# Run tests in CI mode
npm run test:ci

# Run specific test file
npm test -- FileUpload.test.tsx
```

#### Python Service Tests (FastAPI)
```bash
cd python-service

# Activate virtual environment
source venv/bin/activate

# Run all tests
python -m pytest

# Run with coverage
python -m pytest --cov=app

# Run specific test file
python -m pytest tests/test_whisper_service.py

# Run with verbose output
python -m pytest -v
```

### ğŸ”§ Quality Checks

#### Code Formatting & Linting
```bash
# Backend (Java)
./mvnw spotless:check    # Check formatting
./mvnw spotless:apply    # Apply formatting

# Frontend (TypeScript)
npm run lint             # ESLint check
npm run lint:fix         # Auto-fix issues
npm run format           # Prettier formatting

# Python Service
black app/               # Format code
flake8 app/             # Linting
mypy app/               # Type checking
```

#### Security Scanning
```bash
# Backend dependencies
./mvnw dependency-check:check

# Frontend dependencies  
npm audit
npm audit fix

# Python dependencies
safety check
bandit -r app/
```

## ğŸ“Š Monitoring & Observability

### ğŸ¥ Health Checks

Monitor service availability and status:

```bash
# Backend API Health
curl http://localhost:8080/actuator/health
# Response: {"status":"UP","components":{"db":{"status":"UP"}}}

# Python Service Health  
curl http://localhost:8000/health
# Response: {"status":"healthy","model_loaded":true,"uptime":3600.5}

# Frontend Health
# Accessible via browser at http://localhost:3000
# Check browser console for any JavaScript errors
```

### ğŸ“ˆ Performance Metrics

#### Backend Metrics (Spring Boot Actuator)
```bash
# Application metrics
curl http://localhost:8080/actuator/metrics

# Specific metrics
curl http://localhost:8080/actuator/metrics/jvm.memory.used
curl http://localhost:8080/actuator/metrics/http.server.requests
curl http://localhost:8080/actuator/metrics/jdbc.connections.active

# Database health
curl http://localhost:8080/actuator/health/db
```

#### Python Service Metrics
```bash
# Model information
curl http://localhost:8000/model/info

# Memory usage and performance
curl http://localhost:8000/health
```

### ğŸ” Logging & Debugging

#### Log Levels and Configuration
```bash
# Backend - Enable debug logging
export LOGGING_LEVEL_COM_SHANGMIN_WHISPERRR=DEBUG

# Python Service - Enable debug logging  
export LOG_LEVEL=DEBUG

# Frontend - Enable development tools
export REACT_APP_ENABLE_DEBUG=true
```

#### Log Locations
- **Backend**: Console output or configured log file
- **Python Service**: Structured JSON logs to console
- **Frontend**: Browser developer tools console
- **Database**: PostgreSQL log directory

### ğŸš¨ Alerting & Monitoring Setup

#### Recommended Monitoring Stack
```yaml
# docker-compose.monitoring.yml
services:
  prometheus:
    image: prom/prometheus
    ports: ["9090:9090"]
    
  grafana:
    image: grafana/grafana
    ports: ["3001:3000"]
    
  loki:
    image: grafana/loki
    ports: ["3100:3100"]
```

#### Key Metrics to Monitor
- **Response Times**: API endpoint latency
- **Error Rates**: 4xx/5xx HTTP responses  
- **Throughput**: Requests per second
- **Resource Usage**: CPU, memory, disk
- **Queue Depth**: Pending transcription jobs
- **Model Performance**: Transcription accuracy and speed

## ğŸ‘¨â€ğŸ’» Development Guide

### ğŸ¯ Getting Started as a Developer

1. **ğŸ“– Read the Documentation**
   - Start with this README for overview
   - Read [OVERVIEW.md](OVERVIEW.md) for detailed technical architecture
   - Review inline code documentation for implementation details

2. **ğŸ—ï¸ Understand the Architecture**
   - Study the microservices communication flow
   - Learn the database schema and relationships
   - Understand the job lifecycle and state management

3. **ğŸ”§ Set Up Development Environment**
   - Follow the Quick Start guide above
   - Configure your IDE with appropriate plugins
   - Set up debugging and testing tools

### ğŸš€ Adding New Features

#### Backend Development (Spring Boot)
```bash
# 1. Add new endpoint in AudioController.java
@PostMapping("/new-feature")
public ResponseEntity<FeatureResponse> newFeature(@RequestBody FeatureRequest request) {
    // Implementation
}

# 2. Add business logic in AudioService
public interface AudioService {
    FeatureResponse processNewFeature(FeatureRequest request);
}

# 3. Create DTOs for request/response
public class FeatureRequest { /* fields */ }
public class FeatureResponse { /* fields */ }

# 4. Add database entities if needed
@Entity
public class NewEntity extends BaseEntity { /* fields */ }

# 5. Create repository interface
public interface NewEntityRepository extends JpaRepository<NewEntity, Long> {}
```

#### Python Service Development (FastAPI)
```python
# 1. Add new endpoint in main.py
@app.post("/new-feature", response_model=FeatureResponse)
async def new_feature(request: FeatureRequest):
    # Implementation
    
# 2. Add Pydantic models in models.py
class FeatureRequest(BaseModel):
    # fields with validation
    
class FeatureResponse(BaseModel):
    # response fields

# 3. Add business logic in appropriate service class
class NewFeatureService:
    async def process_feature(self, request: FeatureRequest) -> FeatureResponse:
        # Implementation
```

#### Frontend Development (React)
```typescript
// 1. Add API service method in services/transcription.ts
export const TranscriptionService = {
  newFeature: async (request: FeatureRequest): Promise<FeatureResponse> => {
    const response = await apiClient.post('/new-feature', request);
    return response.data;
  }
};

// 2. Create custom hook for state management
export const useNewFeature = () => {
  const mutation = useMutation({
    mutationFn: TranscriptionService.newFeature,
    // configuration
  });
  
  return { /* hook interface */ };
};

// 3. Create React component
export const NewFeatureComponent: React.FC = () => {
  const { newFeature, isLoading, error } = useNewFeature();
  
  return (
    // JSX implementation
  );
};
```

### ğŸ“‹ Code Style Guidelines

#### Java (Spring Boot)
- **Conventions**: Follow Spring Boot and Java naming conventions
- **Documentation**: Comprehensive Javadoc for all public methods
- **Testing**: Unit tests with JUnit 5 and Mockito
- **Formatting**: Use consistent indentation and spacing
- **Architecture**: Maintain layered architecture (Controller â†’ Service â†’ Repository)

#### Python (FastAPI)
- **Style**: Follow PEP 8 with Black auto-formatting
- **Type Hints**: Use type annotations for all function parameters and returns
- **Documentation**: Comprehensive docstrings following Google style
- **Testing**: pytest with async test support
- **Validation**: Pydantic models for all request/response data

#### TypeScript/React
- **Style**: Follow React and TypeScript best practices
- **Components**: Functional components with hooks
- **Types**: Strict TypeScript with proper interface definitions
- **Testing**: Jest and React Testing Library
- **Hooks**: Custom hooks for reusable stateful logic

### ğŸ”„ Development Workflow

#### Git Workflow
```bash
# 1. Create feature branch
git checkout -b feature/new-awesome-feature

# 2. Make changes with descriptive commits
git commit -m "feat: add new transcription model support"

# 3. Push and create pull request
git push origin feature/new-awesome-feature

# 4. Code review and merge
```

#### Testing Strategy
```bash
# Run tests before committing
cd backend && ./mvnw test
cd frontend && npm test  
cd python-service && python -m pytest

# Check code quality
npm run lint
./mvnw spotless:check
black --check app/
```

### ğŸ› Debugging Tips

#### Backend Debugging
- Enable debug logging: `logging.level.com.shangmin.whisperrr=DEBUG`
- Use Spring Boot DevTools for hot reload
- Monitor database queries with `spring.jpa.show-sql=true`
- Use IDE debugger with breakpoints

#### Python Service Debugging  
- Enable debug logging: `LOG_LEVEL=DEBUG`
- Use `pdb` for interactive debugging
- Monitor memory usage for model loading
- Profile performance with `cProfile`

#### Frontend Debugging
- Use React Developer Tools browser extension
- Enable React Query DevTools for state inspection
- Monitor network requests in browser DevTools
- Use TypeScript strict mode for compile-time error catching

## ğŸ¤ Contributing

We welcome contributions to make Whisperrr even better! Here's how you can help:

### ğŸš€ Getting Started

1. **Fork the Repository**
   ```bash
   git clone https://github.com/yourusername/Whisperrr.git
   cd Whisperrr
   ```

2. **Set Up Development Environment**
   - Follow the development setup guide above
   - Ensure all tests pass before making changes
   - Familiarize yourself with the codebase structure

3. **Find Something to Work On**
   - Check the [Issues](../../issues) for open tasks
   - Look for "good first issue" labels for beginners
   - Propose new features via issue discussion

### ğŸ“ Contribution Process

1. **Create a Feature Branch**
   ```bash
   git checkout -b feature/your-feature-name
   ```

2. **Make Your Changes**
   - Write clean, well-documented code
   - Follow existing code style and conventions
   - Add comprehensive tests for new functionality
   - Update documentation as needed

3. **Test Your Changes**
   ```bash
   # Run all tests
   cd backend && ./mvnw test
   cd frontend && npm test
   cd python-service && python -m pytest
   
   # Check code quality
   npm run lint
   ./mvnw spotless:check
   black --check app/
   ```

4. **Commit Your Changes**
   ```bash
   git add .
   git commit -m "feat: add awesome new feature"
   
   # Follow conventional commit format:
   # feat: new feature
   # fix: bug fix
   # docs: documentation changes
   # style: formatting changes
   # refactor: code refactoring
   # test: adding tests
   # chore: maintenance tasks
   ```

5. **Submit a Pull Request**
   - Push your branch to your fork
   - Create a pull request with a clear description
   - Link any related issues
   - Wait for code review and address feedback

### ğŸ¯ Contribution Guidelines

#### Code Quality Standards
- **Documentation**: All public methods must have comprehensive documentation
- **Testing**: New features require corresponding tests
- **Performance**: Consider performance impact of changes
- **Security**: Follow security best practices
- **Accessibility**: Ensure UI changes are accessible

#### Areas for Contribution
- ğŸ› **Bug Fixes**: Help identify and fix issues
- âœ¨ **New Features**: Add new transcription capabilities
- ğŸ“š **Documentation**: Improve guides and API docs
- ğŸ§ª **Testing**: Increase test coverage
- ğŸ¨ **UI/UX**: Enhance user interface and experience
- ğŸš€ **Performance**: Optimize speed and resource usage
- ğŸ”’ **Security**: Strengthen security measures

### ğŸ’¡ Ideas for Contributions

- **Multi-language UI**: Internationalization support
- **Batch Processing**: Upload and process multiple files
- **Export Formats**: Additional export options (SRT, VTT, etc.)
- **Audio Enhancement**: Noise reduction preprocessing
- **Real-time Transcription**: Live audio streaming support
- **User Management**: Authentication and user accounts
- **API Rate Limiting**: Prevent abuse and ensure fair usage
- **Monitoring Dashboard**: Enhanced observability tools

### ğŸ†˜ Getting Help

- **Documentation**: Check [OVERVIEW.md](OVERVIEW.md) for technical details
- **Issues**: Search existing issues or create a new one
- **Discussions**: Use GitHub Discussions for questions
- **Code Review**: Don't hesitate to ask for feedback

### ğŸ† Recognition

Contributors will be recognized in:
- README contributors section
- Release notes for significant contributions
- Special thanks for major features or fixes

Thank you for helping make Whisperrr better! ğŸ‰

## ğŸ“„ License

This project is licensed under the MIT License - see the LICENSE file for details.

## ğŸ†˜ Troubleshooting & Support

### ğŸ”§ Common Issues & Solutions

#### Installation & Setup Issues

**ğŸ Service Startup Issues**
   ```bash
# Issue: Services fail to start
# Solution: Use Docker Compose (handles all dependencies automatically)

# Rebuild and start services
docker compose up -d --build

# Check service logs
docker compose logs -f

# Verify all services are running
docker compose ps
```

**âš™ï¸ Backend Service Issues**
```bash
# Check if backend is running
curl http://localhost:8080/actuator/health

# Verify Python service connectivity
curl http://localhost:8000/health

# Check backend logs
docker compose logs backend

# Restart backend service
docker compose restart backend
```

**ğŸŒ CORS Configuration Issues**
```bash
# Check backend CORS settings
# File: backend/src/main/resources/application.properties
cors.allowed-origins=http://localhost:3000,http://localhost:3001

# Verify frontend URL matches allowed origins
# Check browser developer tools for specific CORS errors
```

#### Runtime Issues

**â³ Transcription Requests Timing Out**
```bash
# Check Python service health
curl http://localhost:8000/health

# Verify model is loaded
curl http://localhost:8000/model/info

# Check system resources
top -p $(pgrep -f "python.*app.main")

# Check backend timeout configuration
grep "whisperrr.service.timeout" backend/src/main/resources/application.properties

# Restart Python service if needed
docker compose restart python-service
```

**ğŸ“ File Upload Failures**
```bash
# Check file size (max 25MB by default)
ls -lh your-audio-file.mp3

# Verify file format is supported
file your-audio-file.mp3

# Check backend logs for specific error
docker compose logs backend

# Test with smaller file or different format
```

**ğŸš« HTTP 413 (Payload Too Large) Errors**
```bash
# Increase backend file size limit
# File: application.properties
spring.servlet.multipart.max-file-size=50MB
spring.servlet.multipart.max-request-size=50MB

# Increase Python service limit
# File: .env
MAX_FILE_SIZE_MB=50

# If using nginx, increase client_max_body_size
client_max_body_size 50M;
```

#### Performance Issues

**ğŸŒ Slow Transcription Processing**
```bash
# Use smaller/faster model
export MODEL_SIZE=base  # instead of large

# Check available memory
free -h

# Reduce concurrent transcriptions
export MAX_CONCURRENT_TRANSCRIPTIONS=1

# Monitor resource usage
docker stats
```

**ğŸ’¾ High Memory Usage**
```bash
# Monitor memory usage
docker stats whisperrr-python

# Check for memory leaks
curl http://localhost:8000/model/info

# Restart services if memory usage is excessive
docker compose restart python-service

# Consider using smaller model
export MODEL_SIZE=tiny
```

### ğŸ” Debugging Tools

#### Enable Debug Logging
```bash
# Backend (Spring Boot)
export LOGGING_LEVEL_COM_SHANGMIN_WHISPERRR=DEBUG
export SPRING_JPA_SHOW_SQL=true

# Python Service
export LOG_LEVEL=DEBUG

# Frontend
export REACT_APP_ENABLE_DEBUG=true
```

#### Health Check Commands
   ```bash
# Check all services
curl http://localhost:3000                    # Frontend
curl http://localhost:8080/actuator/health    # Backend
curl http://localhost:8000/health             # Python Service

# Python service connectivity
curl http://localhost:8000/health

# Docker container status
docker compose ps
```

#### Log Analysis
   ```bash
# View service logs
docker compose logs -f backend
docker compose logs -f python-service
docker compose logs -f frontend

# Follow specific service logs
docker logs -f whisperrr-backend

# Search logs for errors
docker compose logs backend | grep ERROR
```

### ğŸ“ Getting Help

#### Self-Service Resources
1. **ğŸ“– Documentation**
   - [OVERVIEW.md](OVERVIEW.md) - Comprehensive technical guide
   - Inline code documentation in all services
   - API documentation at http://localhost:8000/docs

2. **ğŸ” Search Existing Issues**
   - Check [GitHub Issues](../../issues) for similar problems
   - Search closed issues for solutions
   - Review troubleshooting discussions

#### Community Support
1. **ğŸ› Report Bugs**
   - Create detailed issue with reproduction steps
   - Include system information and logs
   - Provide minimal example if possible

2. **ğŸ’¬ Ask Questions**
   - Use [GitHub Discussions](../../discussions) for general questions
   - Include relevant configuration and error messages
   - Specify your environment (OS, versions, etc.)

3. **ğŸ“§ Contact Information**
   - For security issues: Create private issue or email maintainers
   - For urgent production issues: Include "URGENT" in issue title

#### When Reporting Issues
Please include:
- **Environment**: OS, Python/Java/Node versions
- **Configuration**: Relevant config files (sanitized)
- **Steps to Reproduce**: Clear, minimal reproduction steps
- **Expected vs Actual**: What should happen vs what actually happens
- **Logs**: Relevant error messages and stack traces
- **Screenshots**: For UI-related issues

### ğŸš€ Performance Optimization Tips

#### System Requirements
- **Minimum**: 2GB RAM, 2 CPU cores (no database overhead!)
- **Recommended**: 4GB RAM, 4 CPU cores
- **Optimal**: 8GB RAM, 8 CPU cores (for large models)

#### Optimization Strategies
- Use appropriate Whisper model size for your accuracy needs
- Configure concurrent transcription limits based on available resources
- Monitor and tune JVM heap size for backend service
- Use SSD storage for better I/O performance
- Consider GPU acceleration for Python service (if available)

## ğŸ“š Documentation & Resources

### ğŸ“– Core Documentation
- **[OVERVIEW.md](OVERVIEW.md)** - Comprehensive technical architecture guide
- **[LICENSE](LICENSE)** - MIT License terms and conditions
- **API Documentation** - Interactive docs at http://localhost:8000/docs

### ğŸ”§ Technical Resources
- **[Spring Boot Documentation](https://spring.io/projects/spring-boot)** - Backend framework
- **[FastAPI Documentation](https://fastapi.tiangolo.com/)** - Python service framework  
- **[React Documentation](https://react.dev/)** - Frontend framework
- **[OpenAI Whisper](https://github.com/openai/whisper)** - AI transcription models
- **[PostgreSQL Documentation](https://www.postgresql.org/docs/)** - Database system

### ğŸŒŸ Related Projects
- **[Whisper.cpp](https://github.com/ggerganov/whisper.cpp)** - C++ implementation of Whisper
- **[Faster Whisper](https://github.com/guillaumekln/faster-whisper)** - Optimized Whisper implementation
- **[Whisper JAX](https://github.com/sanchit-gandhi/whisper-jax)** - JAX implementation for TPUs

---

## ğŸ‰ Acknowledgments

### ğŸ™ Special Thanks
- **OpenAI** for the incredible Whisper models
- **Spring Boot Team** for the excellent Java framework
- **FastAPI Team** for the modern Python web framework
- **React Team** for the powerful frontend library
- **PostgreSQL Community** for the robust database system

### ğŸ† Contributors
- **shangmin** - Project creator and maintainer
- *Your name could be here!* - See [Contributing](#-contributing) section

### ğŸ“„ License
This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

### ğŸŒŸ Star History
If you find Whisperrr useful, please consider giving it a star on GitHub! â­

---

<div align="center">

## ğŸŠ Summary

Whisperrr 2.0 represents a significant simplification of the audio transcription platform:

### âœ… **What You Get**
- **Instant transcription results** without any waiting or polling
- **Zero database setup** - just run the services and go
- **Simplified architecture** with fewer moving parts
- **Same high-quality AI transcription** powered by OpenAI Whisper
- **Modern, responsive web interface** with drag-and-drop upload
- **Production-ready deployment** with Docker support

### ğŸš€ **Perfect For**
- **Quick transcription tasks** where you need immediate results
- **Development and testing** without database setup complexity
- **Lightweight deployments** with minimal resource requirements
- **Proof of concepts** and demonstrations
- **Educational purposes** to understand transcription workflows

### ğŸ”„ **Simple Workflow**
1. **Upload** â†’ 2. **Transcribe** â†’ 3. **Results** âœ¨

No job IDs, no polling, no database - just pure, instant transcription!

---

**Built with â¤ï¸ for simplicity and instant results**

[â¬†ï¸ Back to Top](#whisperrr---ai-powered-audio-transcription-platform)

</div>